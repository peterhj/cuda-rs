/* automatically generated by rust-bindgen */

extern "C" {
    #[doc = " \\brief Initialize the CUDA driver API"]
    #[doc = ""]
    #[doc = " Initializes the driver API and must be called before any other function from"]
    #[doc = " the driver API. Currently, the \\p Flags parameter must be 0. If ::cuInit()"]
    #[doc = " has not been called, any function from the driver API will return"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED."]
    #[doc = ""]
    #[doc = " \\param Flags - Initialization flag for CUDA."]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE"]
    #[doc = " \\notefnerr"]
    pub fn cuInit(Flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Returns the latest CUDA version supported by driver"]
    #[doc = ""]
    #[doc = " Returns in \\p *driverVersion the version of CUDA supported by"]
    #[doc = " the driver.  The version is returned as"]
    #[doc = " (1000 &times; major + 10 &times; minor). For example, CUDA 9.2"]
    #[doc = " would be represented by 9020."]
    #[doc = ""]
    #[doc = " This function automatically returns ::CUDA_ERROR_INVALID_VALUE if"]
    #[doc = " \\p driverVersion is NULL."]
    #[doc = ""]
    #[doc = " \\param driverVersion - Returns the CUDA driver version"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa"]
    #[doc = " ::cudaDriverGetVersion,"]
    #[doc = " ::cudaRuntimeGetVersion"]
    pub fn cuDriverGetVersion(driverVersion: *mut ::std::os::raw::c_int) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Returns a handle to a compute device"]
    #[doc = ""]
    #[doc = " Returns in \\p *device a device handle given an ordinal in the range <b>[0,"]
    #[doc = " ::cuDeviceGetCount()-1]</b>."]
    #[doc = ""]
    #[doc = " \\param device  - Returned device handle"]
    #[doc = " \\param ordinal - Device number to get handle for"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa"]
    #[doc = " ::cuDeviceGetAttribute,"]
    #[doc = " ::cuDeviceGetCount,"]
    #[doc = " ::cuDeviceGetName,"]
    #[doc = " ::cuDeviceGetUuid,"]
    #[doc = " ::cuDeviceGetLuid,"]
    #[doc = " ::cuDeviceTotalMem"]
    pub fn cuDeviceGet(device: *mut CUdevice, ordinal: ::std::os::raw::c_int) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Returns the number of compute-capable devices"]
    #[doc = ""]
    #[doc = " Returns in \\p *count the number of devices with compute capability greater"]
    #[doc = " than or equal to 2.0 that are available for execution. If there is no such"]
    #[doc = " device, ::cuDeviceGetCount() returns 0."]
    #[doc = ""]
    #[doc = " \\param count - Returned number of compute-capable devices"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa"]
    #[doc = " ::cuDeviceGetAttribute,"]
    #[doc = " ::cuDeviceGetName,"]
    #[doc = " ::cuDeviceGetUuid,"]
    #[doc = " ::cuDeviceGetLuid,"]
    #[doc = " ::cuDeviceGet,"]
    #[doc = " ::cuDeviceTotalMem,"]
    #[doc = " ::cudaGetDeviceCount"]
    pub fn cuDeviceGetCount(count: *mut ::std::os::raw::c_int) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Returns an identifer string for the device"]
    #[doc = ""]
    #[doc = " Returns an ASCII string identifying the device \\p dev in the NULL-terminated"]
    #[doc = " string pointed to by \\p name. \\p len specifies the maximum length of the"]
    #[doc = " string that may be returned."]
    #[doc = ""]
    #[doc = " \\param name - Returned identifier string for the device"]
    #[doc = " \\param len  - Maximum length of string to store in \\p name"]
    #[doc = " \\param dev  - Device to get identifier string for"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa"]
    #[doc = " ::cuDeviceGetAttribute,"]
    #[doc = " ::cuDeviceGetUuid,"]
    #[doc = " ::cuDeviceGetLuid,"]
    #[doc = " ::cuDeviceGetCount,"]
    #[doc = " ::cuDeviceGet,"]
    #[doc = " ::cuDeviceTotalMem,"]
    #[doc = " ::cudaGetDeviceProperties"]
    pub fn cuDeviceGetName(
        name: *mut ::std::os::raw::c_char,
        len: ::std::os::raw::c_int,
        dev: CUdevice,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Return an UUID for the device"]
    #[doc = ""]
    #[doc = " Returns 16-octets identifing the device \\p dev in the structure"]
    #[doc = " pointed by the \\p uuid."]
    #[doc = ""]
    #[doc = " \\param uuid - Returned UUID"]
    #[doc = " \\param dev  - Device to get identifier string for"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa"]
    #[doc = " ::cuDeviceGetAttribute,"]
    #[doc = " ::cuDeviceGetCount,"]
    #[doc = " ::cuDeviceGetName,"]
    #[doc = " ::cuDeviceGetLuid,"]
    #[doc = " ::cuDeviceGet,"]
    #[doc = " ::cuDeviceTotalMem,"]
    #[doc = " ::cudaGetDeviceProperties"]
    pub fn cuDeviceGetUuid(uuid: *mut CUuuid, dev: CUdevice) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Retain the primary context on the GPU"]
    #[doc = ""]
    #[doc = " Retains the primary context on the device, creating it if necessary,"]
    #[doc = " increasing its usage count. The caller must call"]
    #[doc = " ::cuDevicePrimaryCtxRelease() when done using the context."]
    #[doc = " Unlike ::cuCtxCreate() the newly created context is not pushed onto the stack."]
    #[doc = ""]
    #[doc = " Context creation will fail with ::CUDA_ERROR_UNKNOWN if the compute mode of"]
    #[doc = " the device is ::CU_COMPUTEMODE_PROHIBITED.  The function ::cuDeviceGetAttribute()"]
    #[doc = " can be used with ::CU_DEVICE_ATTRIBUTE_COMPUTE_MODE to determine the compute mode"]
    #[doc = " of the device."]
    #[doc = " The <i>nvidia-smi</i> tool can be used to set the compute mode for"]
    #[doc = " devices. Documentation for <i>nvidia-smi</i> can be obtained by passing a"]
    #[doc = " -h option to it."]
    #[doc = ""]
    #[doc = " Please note that the primary context always supports pinned allocations. Other"]
    #[doc = " flags can be specified by ::cuDevicePrimaryCtxSetFlags()."]
    #[doc = ""]
    #[doc = " \\param pctx  - Returned context handle of the new context"]
    #[doc = " \\param dev   - Device for which primary context is requested"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_OUT_OF_MEMORY,"]
    #[doc = " ::CUDA_ERROR_UNKNOWN"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuDevicePrimaryCtxRelease,"]
    #[doc = " ::cuDevicePrimaryCtxSetFlags,"]
    #[doc = " ::cuCtxCreate,"]
    #[doc = " ::cuCtxGetApiVersion,"]
    #[doc = " ::cuCtxGetCacheConfig,"]
    #[doc = " ::cuCtxGetDevice,"]
    #[doc = " ::cuCtxGetFlags,"]
    #[doc = " ::cuCtxGetLimit,"]
    #[doc = " ::cuCtxPopCurrent,"]
    #[doc = " ::cuCtxPushCurrent,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuCtxSetLimit,"]
    #[doc = " ::cuCtxSynchronize"]
    pub fn cuDevicePrimaryCtxRetain(pctx: *mut CUcontext, dev: CUdevice) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Release the primary context on the GPU"]
    #[doc = ""]
    #[doc = " Releases the primary context interop on the device by decreasing the usage"]
    #[doc = " count by 1. If the usage drops to 0 the primary context of device \\p dev"]
    #[doc = " will be destroyed regardless of how many threads it is current to."]
    #[doc = ""]
    #[doc = " Please note that unlike ::cuCtxDestroy() this method does not pop the context"]
    #[doc = " from stack in any circumstances."]
    #[doc = ""]
    #[doc = " \\param dev - Device which primary context is released"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuDevicePrimaryCtxRetain,"]
    #[doc = " ::cuCtxDestroy,"]
    #[doc = " ::cuCtxGetApiVersion,"]
    #[doc = " ::cuCtxGetCacheConfig,"]
    #[doc = " ::cuCtxGetDevice,"]
    #[doc = " ::cuCtxGetFlags,"]
    #[doc = " ::cuCtxGetLimit,"]
    #[doc = " ::cuCtxPopCurrent,"]
    #[doc = " ::cuCtxPushCurrent,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuCtxSetLimit,"]
    #[doc = " ::cuCtxSynchronize"]
    pub fn cuDevicePrimaryCtxRelease(dev: CUdevice) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Set flags for the primary context"]
    #[doc = ""]
    #[doc = " Sets the flags for the primary context on the device overwriting perviously"]
    #[doc = " set ones. If the primary context is already created"]
    #[doc = " ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE is returned."]
    #[doc = ""]
    #[doc = " The three LSBs of the \\p flags parameter can be used to control how the OS"]
    #[doc = " thread, which owns the CUDA context at the time of an API call, interacts"]
    #[doc = " with the OS scheduler when waiting for results from the GPU. Only one of"]
    #[doc = " the scheduling flags can be set when creating a context."]
    #[doc = ""]
    #[doc = " - ::CU_CTX_SCHED_SPIN: Instruct CUDA to actively spin when waiting for"]
    #[doc = " results from the GPU. This can decrease latency when waiting for the GPU,"]
    #[doc = " but may lower the performance of CPU threads if they are performing work in"]
    #[doc = " parallel with the CUDA thread."]
    #[doc = ""]
    #[doc = " - ::CU_CTX_SCHED_YIELD: Instruct CUDA to yield its thread when waiting for"]
    #[doc = " results from the GPU. This can increase latency when waiting for the GPU,"]
    #[doc = " but can increase the performance of CPU threads performing work in parallel"]
    #[doc = " with the GPU."]
    #[doc = ""]
    #[doc = " - ::CU_CTX_SCHED_BLOCKING_SYNC: Instruct CUDA to block the CPU thread on a"]
    #[doc = " synchronization primitive when waiting for the GPU to finish work."]
    #[doc = ""]
    #[doc = " - ::CU_CTX_BLOCKING_SYNC: Instruct CUDA to block the CPU thread on a"]
    #[doc = " synchronization primitive when waiting for the GPU to finish work. <br>"]
    #[doc = " <b>Deprecated:</b> This flag was deprecated as of CUDA 4.0 and was"]
    #[doc = " replaced with ::CU_CTX_SCHED_BLOCKING_SYNC."]
    #[doc = ""]
    #[doc = " - ::CU_CTX_SCHED_AUTO: The default value if the \\p flags parameter is zero,"]
    #[doc = " uses a heuristic based on the number of active CUDA contexts in the"]
    #[doc = " process \\e C and the number of logical processors in the system \\e P. If"]
    #[doc = " \\e C > \\e P, then CUDA will yield to other OS threads when waiting for"]
    #[doc = " the GPU (::CU_CTX_SCHED_YIELD), otherwise CUDA will not yield while"]
    #[doc = " waiting for results and actively spin on the processor (::CU_CTX_SCHED_SPIN)."]
    #[doc = " However, on low power devices like Tegra, it always defaults to"]
    #[doc = " ::CU_CTX_SCHED_BLOCKING_SYNC."]
    #[doc = ""]
    #[doc = " - ::CU_CTX_LMEM_RESIZE_TO_MAX: Instruct CUDA to not reduce local memory"]
    #[doc = " after resizing local memory for a kernel. This can prevent thrashing by"]
    #[doc = " local memory allocations when launching many kernels with high local"]
    #[doc = " memory usage at the cost of potentially increased memory usage."]
    #[doc = ""]
    #[doc = " \\param dev   - Device for which the primary context flags are set"]
    #[doc = " \\param flags - New flags for the device"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuDevicePrimaryCtxRetain,"]
    #[doc = " ::cuDevicePrimaryCtxGetState,"]
    #[doc = " ::cuCtxCreate,"]
    #[doc = " ::cuCtxGetFlags,"]
    #[doc = " ::cudaSetDeviceFlags"]
    pub fn cuDevicePrimaryCtxSetFlags(dev: CUdevice, flags: ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Get the state of the primary context"]
    #[doc = ""]
    #[doc = " Returns in \\p *flags the flags for the primary context of \\p dev, and in"]
    #[doc = " \\p *active whether it is active.  See ::cuDevicePrimaryCtxSetFlags for flag"]
    #[doc = " values."]
    #[doc = ""]
    #[doc = " \\param dev    - Device to get primary context flags for"]
    #[doc = " \\param flags  - Pointer to store flags"]
    #[doc = " \\param active - Pointer to store context state; 0 = inactive, 1 = active"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa"]
    #[doc = " ::cuDevicePrimaryCtxSetFlags,"]
    #[doc = " ::cuCtxGetFlags,"]
    #[doc = " ::cudaGetDeviceFlags"]
    pub fn cuDevicePrimaryCtxGetState(
        dev: CUdevice,
        flags: *mut ::std::os::raw::c_uint,
        active: *mut ::std::os::raw::c_int,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Destroy all allocations and reset all state on the primary context"]
    #[doc = ""]
    #[doc = " Explicitly destroys and cleans up all resources associated with the current"]
    #[doc = " device in the current process."]
    #[doc = ""]
    #[doc = " Note that it is responsibility of the calling function to ensure that no"]
    #[doc = " other module in the process is using the device any more. For that reason"]
    #[doc = " it is recommended to use ::cuDevicePrimaryCtxRelease() in most cases."]
    #[doc = " However it is safe for other modules to call ::cuDevicePrimaryCtxRelease()"]
    #[doc = " even after resetting the device."]
    #[doc = ""]
    #[doc = " \\param dev - Device for which primary context is destroyed"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_DEVICE,"]
    #[doc = " ::CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuDevicePrimaryCtxRetain,"]
    #[doc = " ::cuDevicePrimaryCtxRelease,"]
    #[doc = " ::cuCtxGetApiVersion,"]
    #[doc = " ::cuCtxGetCacheConfig,"]
    #[doc = " ::cuCtxGetDevice,"]
    #[doc = " ::cuCtxGetFlags,"]
    #[doc = " ::cuCtxGetLimit,"]
    #[doc = " ::cuCtxPopCurrent,"]
    #[doc = " ::cuCtxPushCurrent,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuCtxSetLimit,"]
    #[doc = " ::cuCtxSynchronize,"]
    #[doc = " ::cudaDeviceReset"]
    pub fn cuDevicePrimaryCtxReset(dev: CUdevice) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Returns the CUDA context bound to the calling CPU thread."]
    #[doc = ""]
    #[doc = " Returns in \\p *pctx the CUDA context bound to the calling CPU thread."]
    #[doc = " If no context is bound to the calling CPU thread then \\p *pctx is"]
    #[doc = " set to NULL and ::CUDA_SUCCESS is returned."]
    #[doc = ""]
    #[doc = " \\param pctx - Returned context handle"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa"]
    #[doc = " ::cuCtxSetCurrent,"]
    #[doc = " ::cuCtxCreate,"]
    #[doc = " ::cuCtxDestroy,"]
    #[doc = " ::cudaGetDevice"]
    pub fn cuCtxGetCurrent(pctx: *mut CUcontext) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Returns the device ID for the current context"]
    #[doc = ""]
    #[doc = " Returns in \\p *device the ordinal of the current context\'s device."]
    #[doc = ""]
    #[doc = " \\param device - Returned device ID for the current context"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuCtxCreate,"]
    #[doc = " ::cuCtxDestroy,"]
    #[doc = " ::cuCtxGetApiVersion,"]
    #[doc = " ::cuCtxGetCacheConfig,"]
    #[doc = " ::cuCtxGetFlags,"]
    #[doc = " ::cuCtxGetLimit,"]
    #[doc = " ::cuCtxPopCurrent,"]
    #[doc = " ::cuCtxPushCurrent,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuCtxSetLimit,"]
    #[doc = " ::cuCtxSynchronize,"]
    #[doc = " ::cudaGetDevice"]
    pub fn cuCtxGetDevice(device: *mut CUdevice) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Gets the context\'s API version."]
    #[doc = ""]
    #[doc = " Returns a version number in \\p version corresponding to the capabilities of"]
    #[doc = " the context (e.g. 3010 or 3020), which library developers can use to direct"]
    #[doc = " callers to a specific API version. If \\p ctx is NULL, returns the API version"]
    #[doc = " used to create the currently bound context."]
    #[doc = ""]
    #[doc = " Note that new API versions are only introduced when context capabilities are"]
    #[doc = " changed that break binary compatibility, so the API version and driver version"]
    #[doc = " may be different. For example, it is valid for the API version to be 3020 while"]
    #[doc = " the driver version is 4020."]
    #[doc = ""]
    #[doc = " \\param ctx     - Context to check"]
    #[doc = " \\param version - Pointer to version"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_UNKNOWN"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuCtxCreate,"]
    #[doc = " ::cuCtxDestroy,"]
    #[doc = " ::cuCtxGetDevice,"]
    #[doc = " ::cuCtxGetFlags,"]
    #[doc = " ::cuCtxGetLimit,"]
    #[doc = " ::cuCtxPopCurrent,"]
    #[doc = " ::cuCtxPushCurrent,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuCtxSetLimit,"]
    #[doc = " ::cuCtxSynchronize"]
    pub fn cuCtxGetApiVersion(ctx: CUcontext, version: *mut ::std::os::raw::c_uint) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Loads a compute module"]
    #[doc = ""]
    #[doc = " Takes a filename \\p fname and loads the corresponding module \\p module into"]
    #[doc = " the current context. The CUDA driver API does not attempt to lazily"]
    #[doc = " allocate the resources needed by a module; if the memory for functions and"]
    #[doc = " data (constant and global) needed by the module cannot be allocated,"]
    #[doc = " ::cuModuleLoad() fails. The file should be a \\e cubin file as output by"]
    #[doc = " \\b nvcc, or a \\e PTX file either as output by \\b nvcc or handwritten, or"]
    #[doc = " a \\e fatbin file as output by \\b nvcc from toolchain 4.0 or later."]
    #[doc = ""]
    #[doc = " \\param module - Returned module"]
    #[doc = " \\param fname  - Filename of module to load"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_PTX,"]
    #[doc = " ::CUDA_ERROR_NOT_FOUND,"]
    #[doc = " ::CUDA_ERROR_OUT_OF_MEMORY,"]
    #[doc = " ::CUDA_ERROR_FILE_NOT_FOUND,"]
    #[doc = " ::CUDA_ERROR_NO_BINARY_FOR_GPU,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,"]
    #[doc = " ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuModuleGetFunction,"]
    #[doc = " ::cuModuleGetGlobal,"]
    #[doc = " ::cuModuleGetTexRef,"]
    #[doc = " ::cuModuleLoadData,"]
    #[doc = " ::cuModuleLoadDataEx,"]
    #[doc = " ::cuModuleLoadFatBinary,"]
    #[doc = " ::cuModuleUnload"]
    pub fn cuModuleLoad(module: *mut CUmodule, fname: *const ::std::os::raw::c_char) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Load a module\'s data"]
    #[doc = ""]
    #[doc = " Takes a pointer \\p image and loads the corresponding module \\p module into"]
    #[doc = " the current context. The pointer may be obtained by mapping a \\e cubin or"]
    #[doc = " \\e PTX or \\e fatbin file, passing a \\e cubin or \\e PTX or \\e fatbin file"]
    #[doc = " as a NULL-terminated text string, or incorporating a \\e cubin or \\e fatbin"]
    #[doc = " object into the executable resources and using operating system calls such"]
    #[doc = " as Windows \\c FindResource() to obtain the pointer."]
    #[doc = ""]
    #[doc = " \\param module - Returned module"]
    #[doc = " \\param image  - Module data to load"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_PTX,"]
    #[doc = " ::CUDA_ERROR_OUT_OF_MEMORY,"]
    #[doc = " ::CUDA_ERROR_NO_BINARY_FOR_GPU,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,"]
    #[doc = " ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuModuleGetFunction,"]
    #[doc = " ::cuModuleGetGlobal,"]
    #[doc = " ::cuModuleGetTexRef,"]
    #[doc = " ::cuModuleLoad,"]
    #[doc = " ::cuModuleLoadDataEx,"]
    #[doc = " ::cuModuleLoadFatBinary,"]
    #[doc = " ::cuModuleUnload"]
    pub fn cuModuleLoadData(
        module: *mut CUmodule,
        image: *const ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Load a module\'s data with options"]
    #[doc = ""]
    #[doc = " Takes a pointer \\p image and loads the corresponding module \\p module into"]
    #[doc = " the current context. The pointer may be obtained by mapping a \\e cubin or"]
    #[doc = " \\e PTX or \\e fatbin file, passing a \\e cubin or \\e PTX or \\e fatbin file"]
    #[doc = " as a NULL-terminated text string, or incorporating a \\e cubin or \\e fatbin"]
    #[doc = " object into the executable resources and using operating system calls such"]
    #[doc = " as Windows \\c FindResource() to obtain the pointer. Options are passed as"]
    #[doc = " an array via \\p options and any corresponding parameters are passed in"]
    #[doc = " \\p optionValues. The number of total options is supplied via \\p numOptions."]
    #[doc = " Any outputs will be returned via \\p optionValues."]
    #[doc = ""]
    #[doc = " \\param module       - Returned module"]
    #[doc = " \\param image        - Module data to load"]
    #[doc = " \\param numOptions   - Number of options"]
    #[doc = " \\param options      - Options for JIT"]
    #[doc = " \\param optionValues - Option values for JIT"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_PTX,"]
    #[doc = " ::CUDA_ERROR_OUT_OF_MEMORY,"]
    #[doc = " ::CUDA_ERROR_NO_BINARY_FOR_GPU,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,"]
    #[doc = " ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuModuleGetFunction,"]
    #[doc = " ::cuModuleGetGlobal,"]
    #[doc = " ::cuModuleGetTexRef,"]
    #[doc = " ::cuModuleLoad,"]
    #[doc = " ::cuModuleLoadData,"]
    #[doc = " ::cuModuleLoadFatBinary,"]
    #[doc = " ::cuModuleUnload"]
    pub fn cuModuleLoadDataEx(
        module: *mut CUmodule,
        image: *const ::std::os::raw::c_void,
        numOptions: ::std::os::raw::c_uint,
        options: *mut CUjit_option,
        optionValues: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Load a module\'s data"]
    #[doc = ""]
    #[doc = " Takes a pointer \\p fatCubin and loads the corresponding module \\p module"]
    #[doc = " into the current context. The pointer represents a <i>fat binary</i> object,"]
    #[doc = " which is a collection of different \\e cubin and/or \\e PTX files, all"]
    #[doc = " representing the same device code, but compiled and optimized for different"]
    #[doc = " architectures."]
    #[doc = ""]
    #[doc = " Prior to CUDA 4.0, there was no documented API for constructing and using"]
    #[doc = " fat binary objects by programmers.  Starting with CUDA 4.0, fat binary"]
    #[doc = " objects can be constructed by providing the <i>-fatbin option</i> to \\b nvcc."]
    #[doc = " More information can be found in the \\b nvcc document."]
    #[doc = ""]
    #[doc = " \\param module   - Returned module"]
    #[doc = " \\param fatCubin - Fat binary to load"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_INVALID_PTX,"]
    #[doc = " ::CUDA_ERROR_NOT_FOUND,"]
    #[doc = " ::CUDA_ERROR_OUT_OF_MEMORY,"]
    #[doc = " ::CUDA_ERROR_NO_BINARY_FOR_GPU,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED,"]
    #[doc = " ::CUDA_ERROR_JIT_COMPILER_NOT_FOUND"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuModuleGetFunction,"]
    #[doc = " ::cuModuleGetGlobal,"]
    #[doc = " ::cuModuleGetTexRef,"]
    #[doc = " ::cuModuleLoad,"]
    #[doc = " ::cuModuleLoadData,"]
    #[doc = " ::cuModuleLoadDataEx,"]
    #[doc = " ::cuModuleUnload"]
    pub fn cuModuleLoadFatBinary(
        module: *mut CUmodule,
        fatCubin: *const ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Unloads a module"]
    #[doc = ""]
    #[doc = " Unloads a module \\p hmod from the current context."]
    #[doc = ""]
    #[doc = " \\param hmod - Module to unload"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuModuleGetFunction,"]
    #[doc = " ::cuModuleGetGlobal,"]
    #[doc = " ::cuModuleGetTexRef,"]
    #[doc = " ::cuModuleLoad,"]
    #[doc = " ::cuModuleLoadData,"]
    #[doc = " ::cuModuleLoadDataEx,"]
    #[doc = " ::cuModuleLoadFatBinary"]
    pub fn cuModuleUnload(hmod: CUmodule) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Returns a function handle"]
    #[doc = ""]
    #[doc = " Returns in \\p *hfunc the handle of the function of name \\p name located in"]
    #[doc = " module \\p hmod. If no function of that name exists, ::cuModuleGetFunction()"]
    #[doc = " returns ::CUDA_ERROR_NOT_FOUND."]
    #[doc = ""]
    #[doc = " \\param hfunc - Returned function handle"]
    #[doc = " \\param hmod  - Module to retrieve function from"]
    #[doc = " \\param name  - Name of function to retrieve"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_NOT_FOUND"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuModuleGetGlobal,"]
    #[doc = " ::cuModuleGetTexRef,"]
    #[doc = " ::cuModuleLoad,"]
    #[doc = " ::cuModuleLoadData,"]
    #[doc = " ::cuModuleLoadDataEx,"]
    #[doc = " ::cuModuleLoadFatBinary,"]
    #[doc = " ::cuModuleUnload"]
    pub fn cuModuleGetFunction(
        hfunc: *mut CUfunction,
        hmod: CUmodule,
        name: *const ::std::os::raw::c_char,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Query the context associated with a stream"]
    #[doc = ""]
    #[doc = " Returns the CUDA context that the stream is associated with."]
    #[doc = ""]
    #[doc = " The stream handle \\p hStream can refer to any of the following:"]
    #[doc = " <ul>"]
    #[doc = "   <li>a stream created via any of the CUDA driver APIs such as ::cuStreamCreate"]
    #[doc = "   and ::cuStreamCreateWithPriority, or their runtime API equivalents such as"]
    #[doc = "   ::cudaStreamCreate, ::cudaStreamCreateWithFlags and ::cudaStreamCreateWithPriority."]
    #[doc = "   The returned context is the context that was active in the calling thread when the"]
    #[doc = "   stream was created. Passing an invalid handle will result in undefined behavior.</li>"]
    #[doc = "   <li>any of the special streams such as the NULL stream, ::CU_STREAM_LEGACY and"]
    #[doc = "   ::CU_STREAM_PER_THREAD. The runtime API equivalents of these are also accepted,"]
    #[doc = "   which are NULL, ::cudaStreamLegacy and ::cudaStreamPerThread respectively."]
    #[doc = "   Specifying any of the special handles will return the context current to the"]
    #[doc = "   calling thread. If no context is current to the calling thread,"]
    #[doc = "   ::CUDA_ERROR_INVALID_CONTEXT is returned.</li>"]
    #[doc = " </ul>"]
    #[doc = ""]
    #[doc = " \\param hStream - Handle to the stream to be queried"]
    #[doc = " \\param pctx    - Returned context associated with the stream"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_HANDLE,"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuStreamDestroy,"]
    #[doc = " ::cuStreamCreateWithPriority,"]
    #[doc = " ::cuStreamGetPriority,"]
    #[doc = " ::cuStreamGetFlags,"]
    #[doc = " ::cuStreamWaitEvent,"]
    #[doc = " ::cuStreamQuery,"]
    #[doc = " ::cuStreamSynchronize,"]
    #[doc = " ::cuStreamAddCallback,"]
    #[doc = " ::cudaStreamCreate,"]
    #[doc = " ::cudaStreamCreateWithFlags"]
    pub fn cuStreamGetCtx(hStream: CUstream, pctx: *mut CUcontext) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Launches a CUDA function"]
    #[doc = ""]
    #[doc = " Invokes the kernel \\p f on a \\p gridDimX x \\p gridDimY x \\p gridDimZ"]
    #[doc = " grid of blocks. Each block contains \\p blockDimX x \\p blockDimY x"]
    #[doc = " \\p blockDimZ threads."]
    #[doc = ""]
    #[doc = " \\p sharedMemBytes sets the amount of dynamic shared memory that will be"]
    #[doc = " available to each thread block."]
    #[doc = ""]
    #[doc = " Kernel parameters to \\p f can be specified in one of two ways:"]
    #[doc = ""]
    #[doc = " 1) Kernel parameters can be specified via \\p kernelParams.  If \\p f"]
    #[doc = " has N parameters, then \\p kernelParams needs to be an array of N"]
    #[doc = " pointers.  Each of \\p kernelParams[0] through \\p kernelParams[N-1]"]
    #[doc = " must point to a region of memory from which the actual kernel"]
    #[doc = " parameter will be copied.  The number of kernel parameters and their"]
    #[doc = " offsets and sizes do not need to be specified as that information is"]
    #[doc = " retrieved directly from the kernel\'s image."]
    #[doc = ""]
    #[doc = " 2) Kernel parameters can also be packaged by the application into"]
    #[doc = " a single buffer that is passed in via the \\p extra parameter."]
    #[doc = " This places the burden on the application of knowing each kernel"]
    #[doc = " parameter\'s size and alignment/padding within the buffer.  Here is"]
    #[doc = " an example of using the \\p extra parameter in this manner:"]
    #[doc = " \\code"]
    #[doc = "size_t argBufferSize;"]
    #[doc = "char argBuffer[256];"]
    #[doc = ""]
    #[doc = ""]
    #[doc = "void *config[] = {"]
    #[doc = "CU_LAUNCH_PARAM_BUFFER_POINTER, argBuffer,"]
    #[doc = "CU_LAUNCH_PARAM_BUFFER_SIZE,    &argBufferSize,"]
    #[doc = "CU_LAUNCH_PARAM_END"]
    #[doc = "};"]
    #[doc = "status = cuLaunchKernel(f, gx, gy, gz, bx, by, bz, sh, s, NULL, config);"]
    #[doc = " \\endcode"]
    #[doc = ""]
    #[doc = " The \\p extra parameter exists to allow ::cuLaunchKernel to take"]
    #[doc = " additional less commonly used arguments.  \\p extra specifies a list of"]
    #[doc = " names of extra settings and their corresponding values.  Each extra"]
    #[doc = " setting name is immediately followed by the corresponding value.  The"]
    #[doc = " list must be terminated with either NULL or ::CU_LAUNCH_PARAM_END."]
    #[doc = ""]
    #[doc = " - ::CU_LAUNCH_PARAM_END, which indicates the end of the \\p extra"]
    #[doc = "   array;"]
    #[doc = " - ::CU_LAUNCH_PARAM_BUFFER_POINTER, which specifies that the next"]
    #[doc = "   value in \\p extra will be a pointer to a buffer containing all"]
    #[doc = "   the kernel parameters for launching kernel \\p f;"]
    #[doc = " - ::CU_LAUNCH_PARAM_BUFFER_SIZE, which specifies that the next"]
    #[doc = "   value in \\p extra will be a pointer to a size_t containing the"]
    #[doc = "   size of the buffer specified with ::CU_LAUNCH_PARAM_BUFFER_POINTER;"]
    #[doc = ""]
    #[doc = " The error ::CUDA_ERROR_INVALID_VALUE will be returned if kernel"]
    #[doc = " parameters are specified with both \\p kernelParams and \\p extra"]
    #[doc = " (i.e. both \\p kernelParams and \\p extra are non-NULL)."]
    #[doc = ""]
    #[doc = " Calling ::cuLaunchKernel() sets persistent function state that is"]
    #[doc = " the same as function state set through the following deprecated APIs:"]
    #[doc = "  ::cuFuncSetBlockShape(),"]
    #[doc = "  ::cuFuncSetSharedSize(),"]
    #[doc = "  ::cuParamSetSize(),"]
    #[doc = "  ::cuParamSeti(),"]
    #[doc = "  ::cuParamSetf(),"]
    #[doc = "  ::cuParamSetv()."]
    #[doc = ""]
    #[doc = " When the kernel \\p f is launched via ::cuLaunchKernel(), the previous"]
    #[doc = " block shape, shared size and parameter info associated with \\p f"]
    #[doc = " is overwritten."]
    #[doc = ""]
    #[doc = " Note that to use ::cuLaunchKernel(), the kernel \\p f must either have"]
    #[doc = " been compiled with toolchain version 3.2 or later so that it will"]
    #[doc = " contain kernel parameter information, or have no kernel parameters."]
    #[doc = " If either of these conditions is not met, then ::cuLaunchKernel() will"]
    #[doc = " return ::CUDA_ERROR_INVALID_IMAGE."]
    #[doc = ""]
    #[doc = " \\param f              - Kernel to launch"]
    #[doc = " \\param gridDimX       - Width of grid in blocks"]
    #[doc = " \\param gridDimY       - Height of grid in blocks"]
    #[doc = " \\param gridDimZ       - Depth of grid in blocks"]
    #[doc = " \\param blockDimX      - X dimension of each thread block"]
    #[doc = " \\param blockDimY      - Y dimension of each thread block"]
    #[doc = " \\param blockDimZ      - Z dimension of each thread block"]
    #[doc = " \\param sharedMemBytes - Dynamic shared-memory size per thread block in bytes"]
    #[doc = " \\param hStream        - Stream identifier"]
    #[doc = " \\param kernelParams   - Array of pointers to kernel parameters"]
    #[doc = " \\param extra          - Extra options"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_HANDLE,"]
    #[doc = " ::CUDA_ERROR_INVALID_IMAGE,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_FAILED,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_TIMEOUT,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED"]
    #[doc = " \\note_null_stream"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuCtxGetCacheConfig,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuFuncSetCacheConfig,"]
    #[doc = " ::cuFuncGetAttribute,"]
    #[doc = " ::cudaLaunchKernel"]
    pub fn cuLaunchKernel(
        f: CUfunction,
        gridDimX: ::std::os::raw::c_uint,
        gridDimY: ::std::os::raw::c_uint,
        gridDimZ: ::std::os::raw::c_uint,
        blockDimX: ::std::os::raw::c_uint,
        blockDimY: ::std::os::raw::c_uint,
        blockDimZ: ::std::os::raw::c_uint,
        sharedMemBytes: ::std::os::raw::c_uint,
        hStream: CUstream,
        kernelParams: *mut *mut ::std::os::raw::c_void,
        extra: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Launches a CUDA function where thread blocks can cooperate and synchronize as they execute"]
    #[doc = ""]
    #[doc = " Invokes the kernel \\p f on a \\p gridDimX x \\p gridDimY x \\p gridDimZ"]
    #[doc = " grid of blocks. Each block contains \\p blockDimX x \\p blockDimY x"]
    #[doc = " \\p blockDimZ threads."]
    #[doc = ""]
    #[doc = " \\p sharedMemBytes sets the amount of dynamic shared memory that will be"]
    #[doc = " available to each thread block."]
    #[doc = ""]
    #[doc = " The device on which this kernel is invoked must have a non-zero value for"]
    #[doc = " the device attribute ::CU_DEVICE_ATTRIBUTE_COOPERATIVE_LAUNCH."]
    #[doc = ""]
    #[doc = " The total number of blocks launched cannot exceed the maximum number of blocks per"]
    #[doc = " multiprocessor as returned by ::cuOccupancyMaxActiveBlocksPerMultiprocessor (or"]
    #[doc = " ::cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags) times the number of multiprocessors"]
    #[doc = " as specified by the device attribute ::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT."]
    #[doc = ""]
    #[doc = " The kernel cannot make use of CUDA dynamic parallelism."]
    #[doc = ""]
    #[doc = " Kernel parameters must be specified via \\p kernelParams.  If \\p f"]
    #[doc = " has N parameters, then \\p kernelParams needs to be an array of N"]
    #[doc = " pointers.  Each of \\p kernelParams[0] through \\p kernelParams[N-1]"]
    #[doc = " must point to a region of memory from which the actual kernel"]
    #[doc = " parameter will be copied.  The number of kernel parameters and their"]
    #[doc = " offsets and sizes do not need to be specified as that information is"]
    #[doc = " retrieved directly from the kernel\'s image."]
    #[doc = ""]
    #[doc = " Calling ::cuLaunchCooperativeKernel() sets persistent function state that is"]
    #[doc = " the same as function state set through ::cuLaunchKernel API"]
    #[doc = ""]
    #[doc = " When the kernel \\p f is launched via ::cuLaunchCooperativeKernel(), the previous"]
    #[doc = " block shape, shared size and parameter info associated with \\p f"]
    #[doc = " is overwritten."]
    #[doc = ""]
    #[doc = " Note that to use ::cuLaunchCooperativeKernel(), the kernel \\p f must either have"]
    #[doc = " been compiled with toolchain version 3.2 or later so that it will"]
    #[doc = " contain kernel parameter information, or have no kernel parameters."]
    #[doc = " If either of these conditions is not met, then ::cuLaunchCooperativeKernel() will"]
    #[doc = " return ::CUDA_ERROR_INVALID_IMAGE."]
    #[doc = ""]
    #[doc = " \\param f              - Kernel to launch"]
    #[doc = " \\param gridDimX       - Width of grid in blocks"]
    #[doc = " \\param gridDimY       - Height of grid in blocks"]
    #[doc = " \\param gridDimZ       - Depth of grid in blocks"]
    #[doc = " \\param blockDimX      - X dimension of each thread block"]
    #[doc = " \\param blockDimY      - Y dimension of each thread block"]
    #[doc = " \\param blockDimZ      - Z dimension of each thread block"]
    #[doc = " \\param sharedMemBytes - Dynamic shared-memory size per thread block in bytes"]
    #[doc = " \\param hStream        - Stream identifier"]
    #[doc = " \\param kernelParams   - Array of pointers to kernel parameters"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_HANDLE,"]
    #[doc = " ::CUDA_ERROR_INVALID_IMAGE,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_FAILED,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_TIMEOUT,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,"]
    #[doc = " ::CUDA_ERROR_COOPERATIVE_LAUNCH_TOO_LARGE,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED"]
    #[doc = " \\note_null_stream"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuCtxGetCacheConfig,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuFuncSetCacheConfig,"]
    #[doc = " ::cuFuncGetAttribute,"]
    #[doc = " ::cuLaunchCooperativeKernelMultiDevice,"]
    #[doc = " ::cudaLaunchCooperativeKernel"]
    pub fn cuLaunchCooperativeKernel(
        f: CUfunction,
        gridDimX: ::std::os::raw::c_uint,
        gridDimY: ::std::os::raw::c_uint,
        gridDimZ: ::std::os::raw::c_uint,
        blockDimX: ::std::os::raw::c_uint,
        blockDimY: ::std::os::raw::c_uint,
        blockDimZ: ::std::os::raw::c_uint,
        sharedMemBytes: ::std::os::raw::c_uint,
        hStream: CUstream,
        kernelParams: *mut *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Launches CUDA functions on multiple devices where thread blocks can cooperate and synchronize as they execute"]
    #[doc = ""]
    #[doc = " Invokes kernels as specified in the \\p launchParamsList array where each element"]
    #[doc = " of the array specifies all the parameters required to perform a single kernel launch."]
    #[doc = " These kernels can cooperate and synchronize as they execute. The size of the array is"]
    #[doc = " specified by \\p numDevices."]
    #[doc = ""]
    #[doc = " No two kernels can be launched on the same device. All the devices targeted by this"]
    #[doc = " multi-device launch must be identical. All devices must have a non-zero value for the"]
    #[doc = " device attribute ::CU_DEVICE_ATTRIBUTE_COOPERATIVE_MULTI_DEVICE_LAUNCH."]
    #[doc = ""]
    #[doc = " All kernels launched must be identical with respect to the compiled code. Note that"]
    #[doc = " any __device__, __constant__ or __managed__ variables present in the module that owns"]
    #[doc = " the kernel launched on each device, are independently instantiated on every device."]
    #[doc = " It is the application\'s responsiblity to ensure these variables are initialized and"]
    #[doc = " used appropriately."]
    #[doc = ""]
    #[doc = " The size of the grids as specified in blocks, the size of the blocks themselves"]
    #[doc = " and the amount of shared memory used by each thread block must also match across"]
    #[doc = " all launched kernels."]
    #[doc = ""]
    #[doc = " The streams used to launch these kernels must have been created via either ::cuStreamCreate"]
    #[doc = " or ::cuStreamCreateWithPriority. The NULL stream or ::CU_STREAM_LEGACY or ::CU_STREAM_PER_THREAD"]
    #[doc = " cannot be used."]
    #[doc = ""]
    #[doc = " The total number of blocks launched per kernel cannot exceed the maximum number of blocks"]
    #[doc = " per multiprocessor as returned by ::cuOccupancyMaxActiveBlocksPerMultiprocessor (or"]
    #[doc = " ::cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags) times the number of multiprocessors"]
    #[doc = " as specified by the device attribute ::CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT. Since the"]
    #[doc = " total number of blocks launched per device has to match across all devices, the maximum"]
    #[doc = " number of blocks that can be launched per device will be limited by the device with the"]
    #[doc = " least number of multiprocessors."]
    #[doc = ""]
    #[doc = " The kernels cannot make use of CUDA dynamic parallelism."]
    #[doc = ""]
    #[doc = " The ::CUDA_LAUNCH_PARAMS structure is defined as:"]
    #[doc = " \\code"]
    #[doc = "typedef struct CUDA_LAUNCH_PARAMS_st"]
    #[doc = "{"]
    #[doc = "CUfunction function;"]
    #[doc = "unsigned int gridDimX;"]
    #[doc = "unsigned int gridDimY;"]
    #[doc = "unsigned int gridDimZ;"]
    #[doc = "unsigned int blockDimX;"]
    #[doc = "unsigned int blockDimY;"]
    #[doc = "unsigned int blockDimZ;"]
    #[doc = "unsigned int sharedMemBytes;"]
    #[doc = "CUstream hStream;"]
    #[doc = "void **kernelParams;"]
    #[doc = "} CUDA_LAUNCH_PARAMS;"]
    #[doc = " \\endcode"]
    #[doc = " where:"]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::function specifies the kernel to be launched. All functions must"]
    #[doc = "   be identical with respect to the compiled code."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::gridDimX is the width of the grid in blocks. This must match across"]
    #[doc = "   all kernels launched."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::gridDimY is the height of the grid in blocks. This must match across"]
    #[doc = "   all kernels launched."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::gridDimZ is the depth of the grid in blocks. This must match across"]
    #[doc = "   all kernels launched."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::blockDimX is the X dimension of each thread block. This must match across"]
    #[doc = "   all kernels launched."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::blockDimX is the Y dimension of each thread block. This must match across"]
    #[doc = "   all kernels launched."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::blockDimZ is the Z dimension of each thread block. This must match across"]
    #[doc = "   all kernels launched."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::sharedMemBytes is the dynamic shared-memory size per thread block in bytes."]
    #[doc = "   This must match across all kernels launched."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::hStream is the handle to the stream to perform the launch in. This cannot"]
    #[doc = "   be the NULL stream or ::CU_STREAM_LEGACY or ::CU_STREAM_PER_THREAD. The CUDA context associated"]
    #[doc = "   with this stream must match that associated with ::CUDA_LAUNCH_PARAMS::function."]
    #[doc = " - ::CUDA_LAUNCH_PARAMS::kernelParams is an array of pointers to kernel parameters. If"]
    #[doc = "   ::CUDA_LAUNCH_PARAMS::function has N parameters, then ::CUDA_LAUNCH_PARAMS::kernelParams"]
    #[doc = "   needs to be an array of N pointers. Each of ::CUDA_LAUNCH_PARAMS::kernelParams[0] through"]
    #[doc = "   ::CUDA_LAUNCH_PARAMS::kernelParams[N-1] must point to a region of memory from which the actual"]
    #[doc = "   kernel parameter will be copied. The number of kernel parameters and their offsets and sizes"]
    #[doc = "   do not need to be specified as that information is retrieved directly from the kernel\'s image."]
    #[doc = ""]
    #[doc = " By default, the kernel won\'t begin execution on any GPU until all prior work in all the specified"]
    #[doc = " streams has completed. This behavior can be overridden by specifying the flag"]
    #[doc = " ::CUDA_COOPERATIVE_LAUNCH_MULTI_DEVICE_NO_PRE_LAUNCH_SYNC. When this flag is specified, each kernel"]
    #[doc = " will only wait for prior work in the stream corresponding to that GPU to complete before it begins"]
    #[doc = " execution."]
    #[doc = ""]
    #[doc = " Similarly, by default, any subsequent work pushed in any of the specified streams will not begin"]
    #[doc = " execution until the kernels on all GPUs have completed. This behavior can be overridden by specifying"]
    #[doc = " the flag ::CUDA_COOPERATIVE_LAUNCH_MULTI_DEVICE_NO_POST_LAUNCH_SYNC. When this flag is specified,"]
    #[doc = " any subsequent work pushed in any of the specified streams will only wait for the kernel launched"]
    #[doc = " on the GPU corresponding to that stream to complete before it begins execution."]
    #[doc = ""]
    #[doc = " Calling ::cuLaunchCooperativeKernelMultiDevice() sets persistent function state that is"]
    #[doc = " the same as function state set through ::cuLaunchKernel API when called individually for each"]
    #[doc = " element in \\p launchParamsList."]
    #[doc = ""]
    #[doc = " When kernels are launched via ::cuLaunchCooperativeKernelMultiDevice(), the previous"]
    #[doc = " block shape, shared size and parameter info associated with each ::CUDA_LAUNCH_PARAMS::function"]
    #[doc = " in \\p launchParamsList is overwritten."]
    #[doc = ""]
    #[doc = " Note that to use ::cuLaunchCooperativeKernelMultiDevice(), the kernels must either have"]
    #[doc = " been compiled with toolchain version 3.2 or later so that it will"]
    #[doc = " contain kernel parameter information, or have no kernel parameters."]
    #[doc = " If either of these conditions is not met, then ::cuLaunchCooperativeKernelMultiDevice() will"]
    #[doc = " return ::CUDA_ERROR_INVALID_IMAGE."]
    #[doc = ""]
    #[doc = " \\param launchParamsList - List of launch parameters, one per device"]
    #[doc = " \\param numDevices       - Size of the \\p launchParamsList array"]
    #[doc = " \\param flags            - Flags to control launch behavior"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_HANDLE,"]
    #[doc = " ::CUDA_ERROR_INVALID_IMAGE,"]
    #[doc = " ::CUDA_ERROR_INVALID_VALUE,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_FAILED,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_TIMEOUT,"]
    #[doc = " ::CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING,"]
    #[doc = " ::CUDA_ERROR_COOPERATIVE_LAUNCH_TOO_LARGE,"]
    #[doc = " ::CUDA_ERROR_SHARED_OBJECT_INIT_FAILED"]
    #[doc = " \\note_null_stream"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuCtxGetCacheConfig,"]
    #[doc = " ::cuCtxSetCacheConfig,"]
    #[doc = " ::cuFuncSetCacheConfig,"]
    #[doc = " ::cuFuncGetAttribute,"]
    #[doc = " ::cuLaunchCooperativeKernel,"]
    #[doc = " ::cudaLaunchCooperativeKernelMultiDevice"]
    pub fn cuLaunchCooperativeKernelMultiDevice(
        launchParamsList: *mut CUDA_LAUNCH_PARAMS,
        numDevices: ::std::os::raw::c_uint,
        flags: ::std::os::raw::c_uint,
    ) -> CUresult;
}
extern "C" {
    #[doc = " \\brief Enqueues a host function call in a stream"]
    #[doc = ""]
    #[doc = " Enqueues a host function to run in a stream.  The function will be called"]
    #[doc = " after currently enqueued work and will block work added after it."]
    #[doc = ""]
    #[doc = " The host function must not make any CUDA API calls.  Attempting to use a"]
    #[doc = " CUDA API may result in ::CUDA_ERROR_NOT_PERMITTED, but this is not required."]
    #[doc = " The host function must not perform any synchronization that may depend on"]
    #[doc = " outstanding CUDA work not mandated to run earlier.  Host functions without a"]
    #[doc = " mandated order (such as in independent streams) execute in undefined order"]
    #[doc = " and may be serialized."]
    #[doc = ""]
    #[doc = " For the purposes of Unified Memory, execution makes a number of guarantees:"]
    #[doc = " <ul>"]
    #[doc = "   <li>The stream is considered idle for the duration of the function\'s"]
    #[doc = "   execution.  Thus, for example, the function may always use memory attached"]
    #[doc = "   to the stream it was enqueued in.</li>"]
    #[doc = "   <li>The start of execution of the function has the same effect as"]
    #[doc = "   synchronizing an event recorded in the same stream immediately prior to"]
    #[doc = "   the function.  It thus synchronizes streams which have been \"joined\""]
    #[doc = "   prior to the function.</li>"]
    #[doc = "   <li>Adding device work to any stream does not have the effect of making"]
    #[doc = "   the stream active until all preceding host functions and stream callbacks"]
    #[doc = "   have executed.  Thus, for"]
    #[doc = "   example, a function might use global attached memory even if work has"]
    #[doc = "   been added to another stream, if the work has been ordered behind the"]
    #[doc = "   function call with an event.</li>"]
    #[doc = "   <li>Completion of the function does not cause a stream to become"]
    #[doc = "   active except as described above.  The stream will remain idle"]
    #[doc = "   if no device work follows the function, and will remain idle across"]
    #[doc = "   consecutive host functions or stream callbacks without device work in"]
    #[doc = "   between.  Thus, for example,"]
    #[doc = "   stream synchronization can be done by signaling from a host function at the"]
    #[doc = "   end of the stream.</li>"]
    #[doc = " </ul>"]
    #[doc = ""]
    #[doc = " Note that, in contrast to ::cuStreamAddCallback, the function will not be"]
    #[doc = " called in the event of an error in the CUDA context."]
    #[doc = ""]
    #[doc = " \\param hStream  - Stream to enqueue function call in"]
    #[doc = " \\param fn       - The function to call once preceding stream operations are complete"]
    #[doc = " \\param userData - User-specified data to be passed to the function"]
    #[doc = ""]
    #[doc = " \\return"]
    #[doc = " ::CUDA_SUCCESS,"]
    #[doc = " ::CUDA_ERROR_DEINITIALIZED,"]
    #[doc = " ::CUDA_ERROR_NOT_INITIALIZED,"]
    #[doc = " ::CUDA_ERROR_INVALID_CONTEXT,"]
    #[doc = " ::CUDA_ERROR_INVALID_HANDLE,"]
    #[doc = " ::CUDA_ERROR_NOT_SUPPORTED"]
    #[doc = " \\note_null_stream"]
    #[doc = " \\notefnerr"]
    #[doc = ""]
    #[doc = " \\sa ::cuStreamCreate,"]
    #[doc = " ::cuStreamQuery,"]
    #[doc = " ::cuStreamSynchronize,"]
    #[doc = " ::cuStreamWaitEvent,"]
    #[doc = " ::cuStreamDestroy,"]
    #[doc = " ::cuMemAllocManaged,"]
    #[doc = " ::cuStreamAttachMemAsync,"]
    #[doc = " ::cuStreamAddCallback"]
    pub fn cuLaunchHostFunc(
        hStream: CUstream,
        fn_: CUhostFn,
        userData: *mut ::std::os::raw::c_void,
    ) -> CUresult;
}
